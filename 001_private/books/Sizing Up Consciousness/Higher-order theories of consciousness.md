#core/artificialintelligence #core/appliedneuroscience

A **mental state becomes conscious when it is the object of a higher-order representation**, such as a higher-order thought or perception.

**Motivation**:
- Explain the difference between conscious and unconscious mental states in representational terms, without appealing directly to neural mechanisms.
- Provide a cognitive/representational explanation of consciousness in terms of causal roles and intentional contents of mental representations, fitting with functionalism.
- Avoid saying consciousness is presupposed by or built into first-order mental states themselves. Instead, consciousness arises from a specific representational architecture.
- Characterise consciousness in abstract, mentalistic terms like thoughts and awareness, rather than reducing it directly to neurophysiology.
- Account for the distinction between conscious and unconscious processing in the brain, with consciousness involving higher brain areas representing lower-level activities.

**Main types of higher-order theory**:
1. Higher-order thought (HOT) theories (e.g. Rosenthal): A mental state is conscious when accompanied by a thought about that very state.
2. Higher-order perception (HOP) or “inner sense” theories (e.g. Lycan): The higher-order representation is a kind of internal perceptual state.
3. Self-representational theories (e.g. Kriegel): The higher-order representation is part of the same overall mental state as the conscious state itself.

**Some cited evidence**:
- Role of prefrontal cortex (a higher-order brain area) in conscious report
- Disorders of consciousness that may involve deficits in higher-order representations

**Some objections and debates**:
- Risk of misrepresentation if higher-order state and first-order state can come apart
- Concern that the theories make consciousness too intellectual or demanding
- Debate over whether animals and infants can have the conceptual resources for higher-order representation
- Concern that a regress of higher-order states is required to explain consciousness

> [!NOTE] Difference to lower-order theories like [[Integrated Information Theory]] (IIT)
> Higher-order theories posit that consciousness arises from a higher-order mental state (thought or perception) that is *about* another mental state.  A mental state becomes conscious when you're *aware* of it via this higher-order representation.  In contrast, IIT proposes that consciousness is an intrinsic property of systems that integrate information.  The amount of integrated information (Φ) determines the degree of consciousness.  IIT doesn't require higher-order representations; consciousness is fundamental to the system's capacity for information integration.
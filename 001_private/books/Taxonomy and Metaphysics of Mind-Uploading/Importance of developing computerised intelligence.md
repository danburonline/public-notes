#core/artificialintelligence

![computerised-mind](../../../_inbox/attachments/computerised-mind.jpg)

Developing computerised intelligence is **essential for addressing existential risks, extending human cognitive capacities, and enabling mind uploading as a form of personal continuity.** The argument rests on both practical and philosophical grounds: biological intelligence is fragile, resource-limited, and confined to a single substrate.

## Existential Risk Mitigation

Computerised intelligence offers:

- **Redundancy**: Unlike biological brains, digital systems can be backed up, distributed, and recovered from catastrophic failure
- **Speed**: Electronic processing enables faster response to time-critical threats
- **Scalability**: Cognitive resources can expand beyond biological constraints

See [PSNST](../../_%20general%20knowledge/PSNST.md) for substrate-independent approaches to neural persistence.

## Enabling Mind Uploading

The development of computerised intelligence is a prerequisite for [mind uploading](Mind-uploading%20approaches.md):

1. **Substrate independence**: Demonstrating that cognition can occur in non-biological media
2. **Simulation fidelity**: Achieving sufficient detail to preserve psychological continuity
3. **Verification methods**: Establishing criteria for successful upload (see [Fading qualia](../From%20Biological%20to%20Artificial%20Consciousness/Fading%20qualia.md))

## Philosophical Implications

Questions around [Existential altruism](../../papers/Existential%20altruism.md) arise: if uploaded minds represent continuity of pattern rather than experiential continuity, what obligations do we have toward their development? The [Symbol grounding problem](../How%20To%20Build%20a%20Brain/Symbol%20grounding%20problem.md) also appliesâ€”can computerised systems ground meaning in the same way biological minds do?